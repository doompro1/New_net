{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "from sklearn.datasets import load_boston\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "import plotly\n",
    "import plotly.graph_objs as go\n",
    "import plotly.express as px\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.datasets import make_moons, make_blobs\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.spatial.distance import pdist\n",
    "from scipy.cluster import hierarchy\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn import svm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# в импорте много лишнего , но я его просто скопипастил с др. задания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(load_boston()['filename'], skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _boston_dataset:\n",
      "\n",
      "Boston house prices dataset\n",
      "---------------------------\n",
      "\n",
      "**Data Set Characteristics:**  \n",
      "\n",
      "    :Number of Instances: 506 \n",
      "\n",
      "    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\n",
      "\n",
      "    :Attribute Information (in order):\n",
      "        - CRIM     per capita crime rate by town\n",
      "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
      "        - INDUS    proportion of non-retail business acres per town\n",
      "        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
      "        - NOX      nitric oxides concentration (parts per 10 million)\n",
      "        - RM       average number of rooms per dwelling\n",
      "        - AGE      proportion of owner-occupied units built prior to 1940\n",
      "        - DIS      weighted distances to five Boston employment centres\n",
      "        - RAD      index of accessibility to radial highways\n",
      "        - TAX      full-value property-tax rate per $10,000\n",
      "        - PTRATIO  pupil-teacher ratio by town\n",
      "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
      "        - LSTAT    % lower status of the population\n",
      "        - MEDV     Median value of owner-occupied homes in $1000's\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Creator: Harrison, D. and Rubinfeld, D.L.\n",
      "\n",
      "This is a copy of UCI ML housing dataset.\n",
      "https://archive.ics.uci.edu/ml/machine-learning-databases/housing/\n",
      "\n",
      "\n",
      "This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n",
      "\n",
      "The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\n",
      "prices and the demand for clean air', J. Environ. Economics & Management,\n",
      "vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
      "...', Wiley, 1980.   N.B. Various transformations are used in the table on\n",
      "pages 244-261 of the latter.\n",
      "\n",
      "The Boston house-price data has been used in many machine learning papers that address regression\n",
      "problems.   \n",
      "     \n",
      ".. topic:: References\n",
      "\n",
      "   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n",
      "   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(load_boston()['DESCR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing Attribute Values: None\n",
    "#### 'CRIM' - Уровень преступности на душу населения по городам \n",
    "#### 'ZN' - доля земли под жилую застройку зонирована на участки площадью более 25 000 кв. Футов.\n",
    "#### 'INDUS' - доля акров, не относящихся к розничной торговле, на город\n",
    "#### 'CHAS' - Фиктивная переменная CHAS Charles River (= 1, если участок ограничивает реку; 0 в противном случае)\n",
    "#### 'NOX' - Концентрация оксидов азота NOX (частей на 10 миллионов)\n",
    "#### 'RM' - Среднее количество комнат в доме в РМ\n",
    "#### 'AGE' - Доля домов, занимаемых владельцами, построенных до 1940 г.\n",
    "#### 'DIS' - взвешенные расстояния до пяти бостонских центров занятости\n",
    "#### 'RAD' - Индекс доступности радиальных автомобильных дорог РАД\n",
    "#### 'TAX' - Ставка налога на имущество в размере полной стоимости за 10 000 долларов США.\n",
    "#### 'PTRATIO' - - Соотношение учеников и учителей по городам\n",
    "#### 'B' - доля черных по городам\n",
    "#### 'LSTAT' - более низкий статус населения\n",
    "#### 'MEDV' - Средняя стоимость частных домов в 1000 долларов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX',\n",
       "       'PTRATIO', 'B', 'LSTAT', 'MEDV'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Классификацию предположу согласно параметру CHAS - Фиктивная переменная CHAS Charles River (= 1, если участок ограничивает реку; 0 в противном случае)\n",
    "## Начну  с  модели регресии "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "B:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9705882352941176"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train, df_test = train_test_split(data, test_size=0.2)\n",
    "y_train, y_test = df_train['CHAS'], df_test['CHAS']\n",
    "del df_train['CHAS']\n",
    "del df_test['CHAS']\n",
    "log_reg = LogisticRegression(penalty='l1', dual=False, tol=10 ** -10 , C= 6, fit_intercept=True,\n",
    "                                intercept_scaling=1, class_weight=None, random_state=None, solver='saga', \n",
    "                                max_iter=100, multi_class='auto', verbose= 0, warm_start=False, n_jobs=None, l1_ratio=None)\n",
    "log_reg.fit(df_train, y_train)\n",
    "log_reg.score(df_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "_list = []\n",
    "result_list = []\n",
    "for _ in range(1 , 100):\n",
    "    score_list = []\n",
    "    for __ in range(1 , 10):\n",
    "        clf = DecisionTreeClassifier(max_depth= _)\n",
    "        clf.fit(df_train, y_train)\n",
    "        score_list.append(clf.score(df_test, y_test))\n",
    "    result_list.append(np.mean(score_list))\n",
    "    _list.append(_)\n",
    "res = dict(zip(_list, result_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Резултат 0.9705882352941175 наилучший при  глубине  1\n"
     ]
    }
   ],
   "source": [
    "print(f'Резултат {res[max(res, key=res.get)]} наилучший при  глубине ', max(res, key=res.get))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Одинаково....... хотя изначально казалось , что логистическая регрессия справилась лучше...... ( меня тоже смутило почти  одинаковое число , с разницей в 0.0000000000000001........)\n",
    "# Если я неверно понял задачу - сообщите в комментарии "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Спасибо за проверку!  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
